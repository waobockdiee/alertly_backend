//go:build ignore

package main

import (
	"log"
	"os"

	"alertly/internal/getclusterby"
	"alertly/internal/middleware"
	redisClient "alertly/internal/redis"

	"github.com/gin-gonic/gin"
)

func setupScalableMiddleware(router *gin.Engine) error {
	// ‚úÖ 1. Configurar Redis (opcional, fallback a in-memory)
	redisConfig := redisClient.NewConfig()
	redis, err := redisClient.NewClient(redisConfig)

	if err != nil {
		log.Printf("‚ö†Ô∏è  Redis not available, falling back to in-memory rate limiting: %v", err)

		// ‚úÖ Fallback: Rate limiting in-memory (menos escalable pero funcional)
		if os.Getenv("GIN_MODE") == "release" {
			router.Use(middleware.RateLimitMiddlewareStrict())
		} else {
			router.Use(middleware.RateLimitMiddleware())
		}
	} else {
		log.Println("‚úÖ Redis connected successfully")

		// ‚úÖ Rate limiting distribuido con Redis
		router.Use(middleware.RedisRateLimitMiddleware(redis))
	}

	// ‚úÖ 2. CORS optimizado (O(1) lookup)
	router.Use(middleware.OptimizedCORSMiddleware())

	return nil
}

// Ejemplo de uso en main():
func exampleMain() {
	router := gin.Default()

	// ‚úÖ Setup middleware escalable
	if err := setupScalableMiddleware(router); err != nil {
		log.Fatalf("Failed to setup middleware: %v", err)
	}

	// ‚úÖ Endpoints p√∫blicos con rate limiting espec√≠fico
	publicRoutes := router.Group("/public")

	// Si Redis est√° disponible, usar rate limiting Redis
	// Si no, usar el middleware in-memory existente
	if redis, err := redisClient.NewClient(redisClient.NewConfig()); err == nil {
		publicRoutes.Use(middleware.RedisPublicRateLimitMiddleware(redis))
	} else {
		publicRoutes.Use(middleware.RateLimitMiddlewarePublic())
	}

	publicRoutes.GET("/cluster/getbyid/:incl_id", getclusterby.ViewPublic)

	// ‚úÖ Resto de rutas...

	router.Run(":8080")
}

/*
‚úÖ VENTAJAS DE ESTA IMPLEMENTACI√ìN:

1. üìä ESCALABILIDAD:
   - Redis distribuido para m√∫ltiples instancias
   - O(1) CORS lookup en lugar de O(n)
   - Connection pooling optimizado

2. üõ°Ô∏è RESILENCIA:
   - Fallback autom√°tico si Redis falla
   - Health checks integrados
   - Timeouts configurables

3. ‚ö° PERFORMANCE:
   - Pipeline Redis para operaciones at√≥micas
   - Conexiones reutilizables
   - Headers est√°ticos cacheados

4. üîß CONFIGURABILIDAD:
   - Variables de ambiente
   - Configuraci√≥n por ambiente (dev/prod)
   - Rate limits din√°micos

üìà M√âTRICAS ESPERADAS:
- Desarrollo: 200 req/h por IP
- Producci√≥n: 60 req/h por IP
- Endpoints p√∫blicos: 10-50 req/h por IP
- Latencia CORS: ~0.1ms (vs ~1ms anterior)
- Memoria: Constante (vs crecimiento lineal)
*/
