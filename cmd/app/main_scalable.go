package main

import (
	"log"
	"os"

	"alertly/internal/getclusterby"
	"alertly/internal/middleware"
	redisClient "alertly/internal/redis"

	"github.com/gin-gonic/gin"
)

func setupScalableMiddleware(router *gin.Engine) error {
	// âœ… 1. Configurar Redis (opcional, fallback a in-memory)
	redisConfig := redisClient.NewConfig()
	redis, err := redisClient.NewClient(redisConfig)

	if err != nil {
		log.Printf("âš ï¸  Redis not available, falling back to in-memory rate limiting: %v", err)

		// âœ… Fallback: Rate limiting in-memory (menos escalable pero funcional)
		if os.Getenv("GIN_MODE") == "release" {
			router.Use(middleware.RateLimitMiddlewareStrict())
		} else {
			router.Use(middleware.RateLimitMiddleware())
		}
	} else {
		log.Println("âœ… Redis connected successfully")

		// âœ… Rate limiting distribuido con Redis
		router.Use(middleware.RedisRateLimitMiddleware(redis))
	}

	// âœ… 2. CORS optimizado (O(1) lookup)
	router.Use(middleware.OptimizedCORSMiddleware())

	return nil
}

// Ejemplo de uso en main():
func exampleMain() {
	router := gin.Default()

	// âœ… Setup middleware escalable
	if err := setupScalableMiddleware(router); err != nil {
		log.Fatalf("Failed to setup middleware: %v", err)
	}

	// âœ… Endpoints pÃºblicos con rate limiting especÃ­fico
	publicRoutes := router.Group("/public")

	// Si Redis estÃ¡ disponible, usar rate limiting Redis
	// Si no, usar el middleware in-memory existente
	if redis, err := redisClient.NewClient(redisClient.NewConfig()); err == nil {
		publicRoutes.Use(middleware.RedisPublicRateLimitMiddleware(redis))
	} else {
		publicRoutes.Use(middleware.RateLimitMiddlewarePublic())
	}

	publicRoutes.GET("/cluster/getbyid/:incl_id", getclusterby.ViewPublic)

	// âœ… Resto de rutas...

	router.Run(":8080")
}

/*
âœ… VENTAJAS DE ESTA IMPLEMENTACIÃ“N:

1. ğŸ“Š ESCALABILIDAD:
   - Redis distribuido para mÃºltiples instancias
   - O(1) CORS lookup en lugar de O(n)
   - Connection pooling optimizado

2. ğŸ›¡ï¸ RESILENCIA:
   - Fallback automÃ¡tico si Redis falla
   - Health checks integrados
   - Timeouts configurables

3. âš¡ PERFORMANCE:
   - Pipeline Redis para operaciones atÃ³micas
   - Conexiones reutilizables
   - Headers estÃ¡ticos cacheados

4. ğŸ”§ CONFIGURABILIDAD:
   - Variables de ambiente
   - ConfiguraciÃ³n por ambiente (dev/prod)
   - Rate limits dinÃ¡micos

ğŸ“ˆ MÃ‰TRICAS ESPERADAS:
- Desarrollo: 200 req/h por IP
- ProducciÃ³n: 60 req/h por IP
- Endpoints pÃºblicos: 10-50 req/h por IP
- Latencia CORS: ~0.1ms (vs ~1ms anterior)
- Memoria: Constante (vs crecimiento lineal)
*/
